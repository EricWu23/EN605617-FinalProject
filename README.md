# EN605617-FinalProject
Yujiang's final project of the course introduction to GPU programming at JHU

[![IMAGE ALT TEXT](http://img.youtube.com/vi/gYgdFWtw-68/0.jpg)](http://www.youtube.com/watch?v=gYgdFWtw-68 "Application of GPU in Data Preprocessing and Neural Network Training")

# Project Description
In this project, I explore how to take advantage of CUDA for data preprocessing and Neural Network training.
## For the data preprocessing, I
1. wrote a kernel function in CUDA (grayscaleimagenormalization_kernel.cu)
2. wrote the host side caller (grayscaleimagenormalization_kernel.cu,launch_grayscaleimagenormalization.h)
3. wrote an python,C++ interfacing file (grayscaleimagenormalization_ops.cpp)
4. compiled our custom cuda_module using JIT option
5. normalized the pixel of raw gray scale image,which is between [0,255], to a number between [-1,1] by calling the custom cuda kernel from pytorch

I also compared timing among pixel normalizer function implemented in 
1. pytorch called custom CUDA kernel, 
2. pure pytorch tensor running on CPU, 
3. pure pytorch sensor running on GPU.

Then, I trained a Neural network using pytorch to do dignit recognition based on the data preprocessed by the custom pixel normalizer defined in CUDA kernel.

## For Neural Network Trainig and Testing, I
1. wrote a neural network in C++ targeting CPU operation (Largely borrowed the work from BobMcDear, See reference 1)
2. wrote a neural network in C++/CUDA targeting GPU operation (Largely borrowed the work from BobMcDear, See reference 1)
3. compared time used on CPU and GPU to train NN for MNIST digit recognition


## additional notes:
* *To run the project*, create a new conda environment, install pip under conda environment by `conda install pip`, then type `pip install -r requirements.txt` to install the required python modules 
* The data t10k-images-idx3-ubyte,t10k-labels-idx1-ubyte,train-images-idx3-ubyte,train-labels-idx1-ubyte can be downloaded from http://yann.lecun.com/exdb/mnist/. A local copy is avaliable in the data folder
* The csv datasets used by ./CPU/min_minist.cpp and ./GPU/min_minist.cu are too large to be uploaded onto github. They can be generated by running the ./pytorch/onehotencodelabel.ipynb
* For `CUDA kernel for data preprocessing` and `Neural Network Training for MNIST Digit Recognition using PyTorch`, just run ./pytorch/digitrecognition.ipynb.
* For `CUDA/C++ based Neural Network for MNIST digit recognision`, 
  * run the  ./pytorch/onehotencodelabel.ipynb first to generate the required csv files
  * then use the makefile in ./CPU to compile executable cpukernel 
  * and use makefile in ./GPU to compile executable gpukernel 


## References:
* [Neural network in CUDA/C++](https://github.com/BobMcDear/Neural-Network-CUDA)
* [CUSTOM CUDA Example](https://github.com/godweiyang/NN-CUDA-Example) 
* [CUSTOM C++ AND CUDA EXTENSIONS](https://pytorch.org/tutorials/advanced/cpp_extension.html)
* [MNIST Handwritten Digit Recognition in PyTorch](https://nextjournal.com/gkoehler/pytorch-mnist)
* [pybind11 â€” Seamless operability between C++11 and Python](https://pybind11.readthedocs.io/en/stable/)
* [PyTorch C++ API](https://pytorch.org/cppdocs/api/library_root.html)

